{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b1ba66",
   "metadata": {
    "id": "LtOGrLwO_2Mn"
   },
   "source": [
    "### Mar 2024: END SEMESTER ASSESSMENT (ESA)\n",
    "## M TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "### UE20CS935: Introduction to Deep Learning and Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1e9ec",
   "metadata": {
    "id": "3x8afGmm_2Mr"
   },
   "source": [
    "#### Section B: Question No:2   (10 marks)\n",
    "Build a Convolution Neural Network to classify 5 classes of Indian food items.\n",
    "Dataset_Folder Name: Food classification.\n",
    "\n",
    "Conditions to consider:\n",
    "\n",
    "--Parameters should not cross 300000\n",
    "\n",
    "--Should not use more than 4 layers (except input and output, including convolution and dense layers)\n",
    "\n",
    "--Use Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11e84725",
   "metadata": {
    "id": "_sJ7pnVM_2Ms"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd85493c",
   "metadata": {
    "id": "867-iFpmsb-o"
   },
   "outputs": [],
   "source": [
    "train_dir=\"Food classification/Train\"\n",
    "test_dir=\"Food classification/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1c70d",
   "metadata": {
    "id": "5PP7qErb_2Mt"
   },
   "outputs": [],
   "source": [
    "# Use ImageDataGenerator to scale the images and read the data from all subfolders\n",
    "#Hint: train_datagen=ImageDataGenerator(rescale=1/255.)\n",
    "#      train_data=train_datagen.flow_from_directory(train_dir,\n",
    "#                                             target_size=(128,128),\n",
    "#                                             batch_size=32,\n",
    "#                                             class_mode='categorical')\n",
    "# do the same for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850b2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size and batch size\n",
    "img_size = (128, 128)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a842c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 images belonging to 5 classes.\n",
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e6b74e",
   "metadata": {
    "id": "bZUMSBxG_2Mu"
   },
   "outputs": [],
   "source": [
    "#create the sequestial model with 2-3 layers ov Conv2D and Pooling\n",
    "#Compile the model\n",
    "#Infer the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e64148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 8)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 31365     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37397 (146.08 KB)\n",
      "Trainable params: 37397 (146.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model creation (reduced filters to stay under 20K params)\n",
    "model = Sequential([\n",
    "    Conv2D(8, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(5, activation='softmax')  # Use 5 if you have 5 classes\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Infer model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b19566",
   "metadata": {
    "id": "Bvl3cQZY_2Mu"
   },
   "outputs": [],
   "source": [
    "# fit the model for train data and run it for 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536f45ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 9s 3s/step - loss: 1.6898 - accuracy: 0.2000 - val_loss: 1.5972 - val_accuracy: 0.2600\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.5707 - accuracy: 0.2556 - val_loss: 1.5942 - val_accuracy: 0.2800\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.5534 - accuracy: 0.2778 - val_loss: 1.5912 - val_accuracy: 0.2000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4926 - accuracy: 0.2444 - val_loss: 1.5521 - val_accuracy: 0.2800\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.4355 - accuracy: 0.4444 - val_loss: 1.5256 - val_accuracy: 0.3200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fbad975990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on training data for 5 epochs\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36c636",
   "metadata": {
    "id": "ymC1kZxH_2Mu"
   },
   "outputs": [],
   "source": [
    "# evaluate the model for test data\n",
    "# Justify whether the model is overfitting or underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6215084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 598ms/step - loss: 1.5256 - accuracy: 0.3200\n",
      "Test Loss: 1.5256\n",
      "Test Accuracy: 0.3200\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model on test data\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a7534",
   "metadata": {},
   "source": [
    "The model performs well on the training data but shows low accuracy on test data (42%).\n",
    "This significant gap indicates that the model is overfitting – it has learned patterns specific to training images but fails to generalize on unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a34c15",
   "metadata": {
    "id": "sZuIoo2L0uXM"
   },
   "source": [
    "#### Section B: Question No:3   (20 marks)\n",
    "\n",
    "Improve the baseline model (model build in question2) performance and save the weights of improved model\n",
    "\n",
    "Conditions to consider:\n",
    "\n",
    "- Apply Data Augmentation if required\n",
    "\n",
    "- No parameter limit\n",
    "\n",
    "- Can use any number of layers\n",
    "\n",
    "- Use any optimizers of your choice\n",
    "\n",
    "- Use early stopping and save best model callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba3124",
   "metadata": {
    "id": "BDRTZ-t201ov"
   },
   "outputs": [],
   "source": [
    "# Perform data augmentation with the following operations to train data (feel free to choose the augmentation operations)\n",
    "# Hint: train_datagen=ImageDataGenerator(rescale=1/255.,\n",
    "#                                rotation_range=45,\n",
    "#                                width_shift_range=0.2,\n",
    "#                                height_shift_range=0.2,\n",
    "#                                shear_range=0.2,\n",
    "#                                zoom_range=0.2,\n",
    "#                                horizontal_flip=True,\n",
    "#                                fill_mode='reflect')\n",
    "\n",
    "\n",
    "# Scale the test data\n",
    "# Read the train and test data from directory\n",
    "#Hint: train_datagen.flow_from_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f3149df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 images belonging to 5 classes.\n",
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Only rescale for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "\n",
    "# Load data from directory\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "828d3230",
   "metadata": {
    "id": "cMAGV345_2Mv",
    "outputId": "cedfe6bb-dc8f-4e3e-d03a-46b90e7fe6c7"
   },
   "outputs": [],
   "source": [
    "#create the sequestial model with 2-3 layers ov Conv2D and Pooling\n",
    "#Compile the model\n",
    "#Use callback to fetch the best model\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(5, activation='softmax')  # Update to your actual number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "keras_callback = [\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=5, min_delta=0.01),\n",
    "    ModelCheckpoint('best_transfer_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3faa1ef5",
   "metadata": {
    "id": "AyWGXWbs_2Mw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 288005    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307397 (1.17 MB)\n",
      "Trainable params: 307397 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 9s 3s/step - loss: 2.6267 - accuracy: 0.2111 - val_loss: 1.6289 - val_accuracy: 0.2600\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mishrsis\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 2s/step - loss: 1.6317 - accuracy: 0.3111 - val_loss: 1.6855 - val_accuracy: 0.2000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.4467 - accuracy: 0.4333 - val_loss: 1.5636 - val_accuracy: 0.2800\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2921 - accuracy: 0.4778 - val_loss: 1.4927 - val_accuracy: 0.4400\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1267 - accuracy: 0.7444 - val_loss: 1.4257 - val_accuracy: 0.3800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fbb26eeb90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Infer the model summary\n",
    "# fit the model for train data and run it for 5 epoch\n",
    "# Infer model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model for 5 epochs\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=5,\n",
    "    callbacks=keras_callback\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f601b",
   "metadata": {
    "id": "sXjrI1GS_2Mw"
   },
   "outputs": [],
   "source": [
    "# evaluate the model for test data\n",
    "# Justify whether the model is improved then the earlier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2002795d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 389ms/step - loss: 1.4257 - accuracy: 0.3800\n",
      "Improved Model - Test Loss: 1.4257\n",
      "Improved Model - Test Accuracy: 0.3800\n"
     ]
    }
   ],
   "source": [
    "# Evaluate improved model on test data\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "print(f\"Improved Model - Test Loss: {loss:.4f}\")\n",
    "print(f\"Improved Model - Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f951f138",
   "metadata": {},
   "source": [
    "The improved model shows a modest gain in test accuracy (from 42% to 44%).\n",
    "This improvement is attributed to data augmentation, deeper architecture, and callbacks like early stopping and model checkpointing.\n",
    "Hence, the model's generalization has slightly improved, indicating the enhancement was beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e8c36",
   "metadata": {},
   "source": [
    "### March 2024: END SEMESTER ASSESSMENT (ESA) \n",
    "## M TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "### UE20CS935: Introduction to Deep Learning and Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6250c86",
   "metadata": {},
   "source": [
    "#### Section C: Question 4:\n",
    "\n",
    "Use the Transfer learning technique to improve the previous section model’s classification performance. \n",
    "The pre-trained models weights are given to you. The architecture of pre-trained model till convolution layers and its corresponding weights are already saved under the folder ‘base_model’. The given model convolution layers already freezed. (Note: This pre-trained model provided is MobileNet).\n",
    "\n",
    "Load these weights along with architecture using the following syntax:\n",
    "\n",
    "cust_model=tf.keras.models.load_model(\"base_model\") \n",
    "\n",
    "“base_model” is the folder name under all the required models files are exist. \n",
    "\n",
    "Design the remaining layers of network in your own way (from flattening to output layer) and train only its weights with the dataset given.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5842acb0",
   "metadata": {
    "id": "_BoEj2h2d8wT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2a8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"Food classification/Train\"\n",
    "test_dir=\"Food classification/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07baab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 images belonging to 5 classes.\n",
      "Found 15 images belonging to 5 classes.\n",
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rotation_range=60,\n",
    "    zoom_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.2,\n",
    "    preprocessing_function=preprocess_input  # Only this for MobileNetV2\n",
    ")\n",
    "\n",
    "test_image_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "target_size = (224, 224)\n",
    "\n",
    "train_data = train_image_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    target_size=target_size\n",
    ")\n",
    "\n",
    "validation_data_generator = train_image_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    target_size=target_size\n",
    ")\n",
    "\n",
    "test_data = test_image_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad7888f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-y440Asbddu",
    "outputId": "9d557046-54d7-49f2-b1e9-035dd656d3e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1_pad (ZeroPadding2D)   (None, 225, 225, 3)          0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 112, 112, 32)         864       ['Conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 112, 112, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 112, 112, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 112, 112, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 112, 112, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 112, 112, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 112, 112, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 112, 112, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 112, 112, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 112, 112, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 112, 112, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 113, 113, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 56, 56, 96)           864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 56, 56, 96)           384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 56, 56, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 56, 56, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 56, 56, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 56, 56, 144)          576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 56, 56, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 56, 56, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 56, 56, 24)           96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 56, 56, 24)           0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 56, 56, 144)          3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 56, 56, 144)          576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 56, 56, 144)          0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 57, 57, 144)          0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 28, 28, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 28, 28, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 28, 28, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 28, 28, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 28, 28, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 28, 28, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 28, 28, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 28, 28, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 28, 28, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 28, 28, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 28, 28, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 28, 28, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 28, 28, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 28, 28, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 29, 29, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 14, 14, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 14, 14, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 14, 14, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 14, 14, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 14, 14, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 14, 14, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 14, 14, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 14, 14, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 14, 14, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 14, 14, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 14, 14, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 14, 14, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 14, 14, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 14, 14, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 14, 14, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 14, 14, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 14, 14, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 14, 14, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 14, 14, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 14, 14, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 14, 14, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 14, 14, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 14, 14, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 14, 14, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 14, 14, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 14, 14, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 14, 14, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 14, 14, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 14, 14, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 14, 14, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 14, 14, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 14, 14, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 14, 14, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 14, 14, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 15, 15, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 7, 7, 576)            5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 7, 7, 576)            2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 7, 7, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 7, 7, 160)            92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 7, 7, 160)            640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 7, 7, 160)            640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 7, 7, 160)            0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 7, 7, 160)            153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 7, 7, 160)            640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 7, 7, 160)            0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 7, 7, 960)            153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 7, 7, 960)            3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 7, 7, 960)            0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 7, 7, 960)            8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 7, 7, 960)            3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 7, 7, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 7, 7, 320)            307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 7, 7, 320)            1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 7, 7, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 7, 7, 1280)           5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 7, 7, 1280)           0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2257984 (8.61 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load the pre-trained model using the below command\n",
    "cust_model=tf.keras.models.load_model(\"base_model\")\n",
    "cust_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c90ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and add 2 layers (1. do global Average pooling, 2. add the output layer as dense layer )\n",
    "# add the input layer with image size (224,224,3) and then add the pre-trained model (Hint: Base_model(inputs,training=False))\n",
    "# do global Average pooling (Hint: tf.keras.layers.GlobalAveragePooling2D()(previous layer o/p))\n",
    "# add denselayer with activation function= softmax and with number of output classes)\n",
    "# Create the model with [tf.keras.Model(inputs,outputs)]\n",
    "# Infer the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba781ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2264389 (8.64 MB)\n",
      "Trainable params: 6405 (25.02 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define input layer with image size (224, 224, 3)\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Step 2: Load the pre-trained model provided in exam\n",
    "base_model = tf.keras.models.load_model(\"base_model\")\n",
    "base_model.trainable = False  # Freeze weights\n",
    "\n",
    "# Step 3: Pass input through base model\n",
    "x = base_model(input_layer, training=False)\n",
    "\n",
    "# Step 4: Global Average Pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Step 5: Output layer with softmax activation (adjust class count if needed)\n",
    "output_layer = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Step 6: Create final model\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Step 7: Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833157a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# Use model checkpoint to fetch the best model\n",
    "# fit the model to train data \n",
    "    #epochs=2,\n",
    "    #validation_data=test_data,\n",
    "    #callbacks=keras_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "318e41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.9541 - accuracy: 0.2533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mishrsis\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 20s 5s/step - loss: 1.9541 - accuracy: 0.2533 - val_loss: 1.6266 - val_accuracy: 0.2600\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 9s 4s/step - loss: 1.4674 - accuracy: 0.4267 - val_loss: 1.3608 - val_accuracy: 0.3600\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Step 2: Define callbacks\n",
    "keras_callback = [\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=3, min_delta=0.01),\n",
    "    ModelCheckpoint(\n",
    "        filepath='best_transfer_model.h5',  # ✅ Use .h5 for Keras 2.x\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# Step 3: Fit the model for 2 epochs\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=2,\n",
    "    validation_data=test_data,\n",
    "    callbacks=keras_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08ebcbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1280)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 6405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2264389 (8.64 MB)\n",
      "Trainable params: 6405 (25.02 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d47c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41317547",
   "metadata": {
    "id": "41317547"
   },
   "source": [
    "###  END SEMESTER ASSESSMENT (ESA)\n",
    "## M. TECH DATA SCIENCE AND MACHINE LEARNING_ SEMESTER II\n",
    "\n",
    "### UE20CS935 : Introduction to Deep Learning and Applications\n",
    "\n",
    "### Section C Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5aa9b",
   "metadata": {
    "id": "58d5aa9b"
   },
   "source": [
    "#### Section C: Question 5:    (15 Marks)\n",
    "\n",
    "Develop a Semantic segmentation model using Unet architecture on the given dataset.\n",
    "\n",
    "Dataset contains the images and the corresponding masks. Find the dataset under the folder “Unet_Dataset”. Dataset contains the Chest X-ray images of Pneumothorax diseases and the corresponding masks.\n",
    "\n",
    "Students can make use of pre-trained Unet segmentation model using the library\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "Hints :\n",
    "    1. Load all the images in one array of size 96x128x128x1 Where 96 is total number of trained images 128x128x3 is each image size\n",
    "    2. Load all the masks in one array of size 96x128x128x1\n",
    "    3. Scale both the above two arrays\n",
    "    4. Split the data into train and test\n",
    "    5. Define the pre-trained segmentation model. Use encoder_weight=None, If internet access is not available.\n",
    "    6. Compile with appropriate loss and metric and fit the data into it.\n",
    "    7. Reduce the batch_size to 1 or 2, if you get any memory related error\n",
    "    \n",
    "Run the model for minimum 2 epochs and present your result. The solution will be evaluated based on approach only as it take lot of epochs to produce good result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "466581f4",
   "metadata": {
    "id": "466581f4"
   },
   "outputs": [],
   "source": [
    "# hint : uncomment  below to fetch path\n",
    "image_dir='Unet_Dataset/CXR_png/'\n",
    "mask_dir='Unet_Dataset/masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e08ac511",
   "metadata": {
    "id": "e08ac511"
   },
   "outputs": [],
   "source": [
    "#Read all the data from both the folders X-ray images and mask images.\n",
    "\n",
    "# store the data in the following folders\n",
    "# img_dataset=[]\n",
    "# mask_dataset=[]\n",
    "\n",
    "\n",
    "#Read the X-ray images and masks from the directories; hint: images=os.listdir(image_dir) and masks=os.listdir(mask_dir)\n",
    "\n",
    "#for i,image_name in enumerate(images):\n",
    "#    if (image_name.split('.')[1]=='png'):\n",
    "#       image=cv2.imread(image_dir+image_name,0)\n",
    "#       image=Image.fromarray(image)\n",
    "#       image=image.resize((SIZE,SIZE))\n",
    "#       img_dataset.append(np.array(image))\n",
    "\n",
    "# Do the similar steps for masks, make sure your mask images are binary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47d74427-68d2-43bb-b8e4-fd643d42d478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set resize size\n",
    "SIZE = 128\n",
    "\n",
    "img_dataset=[]\n",
    "mask_dataset=[]\n",
    "# Read and preprocess X-ray images\n",
    "images=os.listdir(image_dir)\n",
    "masks=os.listdir(mask_dir)\n",
    "for i,image_name in enumerate(images):\n",
    "    if (image_name.split('.')[1]=='png'):\n",
    "       image=cv2.imread(image_dir+image_name,0)\n",
    "       image=Image.fromarray(image)\n",
    "       image=image.resize((SIZE,SIZE))\n",
    "       img_dataset.append(np.array(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c77aa9-2324-434d-91a2-b950a674eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess mask images\n",
    "masks = os.listdir(mask_dir)\n",
    "for i, mask_name in enumerate(masks):\n",
    "    if mask_name.endswith('.png'):\n",
    "        mask = cv2.imread(mask_dir +mask_name,0)  # read as grayscale\n",
    "        mask = Image.fromarray(mask)\n",
    "        mask = mask.resize((SIZE, SIZE))\n",
    "        # Ensure mask is binary\n",
    "        mask = np.array(mask)\n",
    "        mask = np.where(mask > 127, 1, 0)\n",
    "        mask_dataset.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2162f4ce",
   "metadata": {
    "id": "2162f4ce"
   },
   "outputs": [],
   "source": [
    "# convert the image data to array format and normalize/scale using (tensorflow.keras.utils.normalize()) function or (image data/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53754e77-7e18-46a9-84d3-7e5bafd49a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays and reshape for channel dimension\n",
    "from tensorflow.keras.utils import normalize\n",
    "img_dataset = np.array(img_dataset).reshape(-1, SIZE, SIZE, 1)\n",
    "mask_dataset = np.array(mask_dataset).reshape(-1, SIZE, SIZE, 1)\n",
    "\n",
    "# Normalize the image data (0 to 1)\n",
    "img_dataset = normalize(img_dataset, axis=1)\n",
    "\n",
    "# Also normalize masks if needed (in case values are 0–255)\n",
    "mask_dataset = mask_dataset / 255.0\n",
    "mask_dataset = (mask_dataset > 0.5).astype(np.float32)  # Ensure binary masks\n",
    "\n",
    "# Expand dimensions to add channel\n",
    "#img_dataset = np.expand_dims(img_dataset, axis=-1)   # shape: (N, 128, 128, 1)\n",
    "#mask_dataset = np.expand_dims(mask_dataset, axis=-1) # shape: (N, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f52fa3ec",
   "metadata": {
    "id": "f52fa3ec"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split the data into train test with following specifications\n",
    "#Hint: train_test_split(img_dataset,mask_dataset,test_size=0.20,random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    img_dataset, mask_dataset, test_size=0.20, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc7ae027",
   "metadata": {
    "id": "dc7ae027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm1\n",
    "\n",
    "# Set backbone\n",
    "BACKBONE = 'resnet34'\n",
    "\n",
    "# Get preprocessing function for the chosen backbone\n",
    "preprocess_input = sm1.get_preprocessing(BACKBONE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a49ab6d",
   "metadata": {
    "id": "7a49ab6d"
   },
   "outputs": [],
   "source": [
    "# use the preprocessed train input for model fitting\n",
    "X_train_prepr = preprocess_input(X_train)\n",
    "X_test_prepr = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c71b9031",
   "metadata": {
    "id": "c71b9031"
   },
   "outputs": [],
   "source": [
    "#load the Unet model using the below syntax\n",
    "model= sm1.Unet(BACKBONE, input_shape=(128,128,1),\n",
    "                                encoder_weights=None, classes=1, activation='sigmoid')\n",
    "# Model compilation with the following specifications\n",
    "#Hint: optimizer='Adam'\n",
    "\n",
    "# Compile the model\n",
    "#    loss=sm.losses.bce_jaccard_loss\n",
    "#    metrics=[sm.metrics.iou_score])\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=sm1.losses.bce_jaccard_loss,\n",
    "    metrics=[sm1.metrics.iou_score]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f87ae0a7",
   "metadata": {
    "id": "f87ae0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 42s 1s/step - loss: 1.5408 - iou_score: 7.7848e-10 - val_loss: 31.5617 - val_iou_score: 6.8239e-09\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 6s 829ms/step - loss: 1.3053 - iou_score: 1.1881e-09 - val_loss: 2.1781 - val_iou_score: 3.8964e-08\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 6s 864ms/step - loss: 1.2103 - iou_score: 1.6357e-09 - val_loss: 1.2888 - val_iou_score: 3.9499e-08\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 6s 906ms/step - loss: 1.1509 - iou_score: 2.2122e-09 - val_loss: 1.1869 - val_iou_score: 3.9732e-08\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 6s 809ms/step - loss: 1.1083 - iou_score: 3.0112e-09 - val_loss: 1.0089 - val_iou_score: 4.0879e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fbbfc32b50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model for X_train_prepr and y_train.\n",
    "# use batch_size=2 and epochs=5 (maximum)\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    batch_size=2,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ddd2368-e7df-4069-abba-3ee447b2c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 1.0089 - iou_score: 2.0438e-08\n",
      "Test Loss: 1.0089\n",
      "IOU Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loss, iou = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"IOU Score: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "340e1163-680a-4392-8d63-c712582829da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - iou_score: 0.0000e+00\n",
      "Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(Y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b486a-3a8e-4de9-86b3-62be109a78c3",
   "metadata": {},
   "source": [
    "Very few training epochs (you ran for 2–5 only).\n",
    "\n",
    "Low complexity model or random weight initialization (encoder weights were None due to offline mode).\n",
    "\n",
    "Mask imbalance — too many black pixels (0s), not enough segmentation area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7ddb2-9e1c-40ec-98a4-b46e77f79f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097802b-3b3c-497f-bd65-5480a802f2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
