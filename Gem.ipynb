{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c70de54-5153-4ee3-a352-455f635a8cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.173.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.5.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.69.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mishrsis\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "   ---------------------------------------- 0.0/155.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  153.6/155.4 kB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 155.4/155.4 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.1/1.3 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.7/1.3 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.2/1.3 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 160.8/160.8 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.173.0-py3-none-any.whl (13.6 MB)\n",
      "   ---------------------------------------- 0.0/13.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.6 MB 20.5 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.9/13.6 MB 11.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/13.6 MB 10.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/13.6 MB 11.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/13.6 MB 10.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.0/13.6 MB 10.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.3/13.6 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.7/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.1/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.3/13.6 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.8/13.6 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.3/13.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.9/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.4/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.8/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.2/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.7/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 8.2/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.6/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.1/13.6 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.4/13.6 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.8/13.6 MB 10.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.1/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.5/13.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.9/13.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.8/13.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.2/13.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.6/13.6 MB 10.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.9/13.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.4/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.6/13.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.6/13.6 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "   ---------------------------------------- 0.0/294.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 294.5/294.5 kB 6.0 MB/s eta 0:00:00\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.2/50.2 kB ? eta 0:00:00\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.8 kB ? eta -:--:--\n",
      "   ---------------------------------- ---- 389.1/434.8 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.8/434.8 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.73.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.6/4.3 MB 17.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.8/4.3 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.2/4.3 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 11.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.2/4.3 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.4/4.3 MB 10.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.8/4.3 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.2/4.3 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.6/4.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.9/4.3 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.3 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 9.2 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.69.0\n",
      "    Uninstalling grpcio-1.69.0:\n",
      "      Successfully uninstalled grpcio-1.69.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.1 google-api-python-client-2.173.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.73.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mishrsis\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\mishrsis\\AppData\\Local\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.30.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n",
      "streamlit 1.30.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.5 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6cebe2d-4749-4c75-8437-12c832f216e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from IPython.display import Markdown # Optional: for pretty printing Markdown output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f20259-bcc8-4bb3-9620-32e86aafc5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini Models:\n",
      "- models/gemini-1.0-pro-vision-latest (Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.)\n",
      "- models/gemini-pro-vision (Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.)\n",
      "- models/gemini-1.5-pro-latest (Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.)\n",
      "- models/gemini-1.5-pro-002 (Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.)\n",
      "- models/gemini-1.5-pro (Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.)\n",
      "- models/gemini-1.5-flash-latest (Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.)\n",
      "- models/gemini-1.5-flash (Description: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.)\n",
      "- models/gemini-1.5-flash-002 (Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.)\n",
      "- models/gemini-1.5-flash-8b (Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.)\n",
      "- models/gemini-1.5-flash-8b-001 (Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.)\n",
      "- models/gemini-1.5-flash-8b-latest (Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.)\n",
      "- models/gemini-2.5-pro-exp-03-25 (Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.5-pro-preview-03-25 (Description: Gemini 2.5 Pro Preview 03-25)\n",
      "- models/gemini-2.5-flash-preview-04-17 (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.5-flash-preview-05-20 (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.5-flash (Description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.)\n",
      "- models/gemini-2.5-flash-preview-04-17-thinking (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.5-flash-lite-preview-06-17 (Description: Preview release (June 11th, 2025) of Gemini 2.5 Flash Lite)\n",
      "- models/gemini-2.5-pro-preview-05-06 (Description: Preview release (May 6th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.5-pro-preview-06-05 (Description: Preview release (June 5th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.5-pro (Description: Stable release (June 17th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.0-flash-exp (Description: Gemini 2.0 Flash Experimental)\n",
      "- models/gemini-2.0-flash (Description: Gemini 2.0 Flash)\n",
      "- models/gemini-2.0-flash-001 (Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.)\n",
      "- models/gemini-2.0-flash-exp-image-generation (Description: Gemini 2.0 Flash (Image Generation) Experimental)\n",
      "- models/gemini-2.0-flash-lite-001 (Description: Stable version of Gemini 2.0 Flash Lite)\n",
      "- models/gemini-2.0-flash-lite (Description: Gemini 2.0 Flash-Lite)\n",
      "- models/gemini-2.0-flash-preview-image-generation (Description: Gemini 2.0 Flash Preview Image Generation)\n",
      "- models/gemini-2.0-flash-lite-preview-02-05 (Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite)\n",
      "- models/gemini-2.0-flash-lite-preview (Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite)\n",
      "- models/gemini-2.0-pro-exp (Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.0-pro-exp-02-05 (Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-exp-1206 (Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro)\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21 (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.0-flash-thinking-exp (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.0-flash-thinking-exp-1219 (Description: Preview release (April 17th, 2025) of Gemini 2.5 Flash)\n",
      "- models/gemini-2.5-flash-preview-tts (Description: Gemini 2.5 Flash Preview TTS)\n",
      "- models/gemini-2.5-pro-preview-tts (Description: Gemini 2.5 Pro Preview TTS)\n",
      "- models/learnlm-2.0-flash-experimental (Description: LearnLM 2.0 Flash Experimental)\n",
      "- models/gemma-3-1b-it (Description: )\n",
      "- models/gemma-3-4b-it (Description: )\n",
      "- models/gemma-3-12b-it (Description: )\n",
      "- models/gemma-3-27b-it (Description: )\n",
      "- models/gemma-3n-e4b-it (Description: )\n",
      "\n",
      "Using model: gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "sishishira = \"AIzaSyAT3PPOZzhXn4h2Lcs9vMRDsqhMf\" # <<< REPLACE WITH YOUR KEY!\n",
    "\n",
    "# Configure and list available models\n",
    "genai.configure(api_key=sishishira)\n",
    "\n",
    "print(\"Available Gemini Models:\")\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(f\"- {m.name} (Description: {m.description})\")\n",
    "\n",
    "# Choose a model\n",
    "model_name = 'gemini-1.5-flash'\n",
    "gemini_model = genai.GenerativeModel(model_name)\n",
    "print(f\"\\nUsing model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61726e64-c042-4f2a-b961-07c4b9023c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Exam Question ---\n",
      "Question: What is an activation function in a neural network? Explain its purpose, common types (ReLU, Sigmoid, Tanh), and why non-linearity is important.\n",
      "Word Limit: 500\n",
      "\n",
      "--- Sending Prompt to Gemini Model ---\n",
      "What is an activation function in a neural network? Explain its purpose, common types (ReLU, Sigmoid, Tanh), and why non-linearity is important.. Generate the response within 500 words.\n",
      "\n",
      "--- Gemini Response Received (442 words) ---\n",
      "\n",
      "--- FINAL EXAM ANSWER ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In a neural network, an activation function is a crucial component that introduces non-linearity into the network's output.  Without activation functions, each layer would simply perform a linear transformation on the input, and no matter how many layers you stack, the entire network would effectively be just one linear transformation. This severely limits the network's ability to learn complex patterns in data.\n",
       "\n",
       "The purpose of an activation function is to transform the linear output of a neuron into a non-linear output. This non-linear transformation allows the network to learn and approximate arbitrarily complex functions, enabling it to solve a wide range of problems.  The output of the activation function then becomes the input for the next layer.\n",
       "\n",
       "Several common activation functions are used:\n",
       "\n",
       "* **Sigmoid:**  This function outputs a value between 0 and 1, often interpreted as a probability. Its formula is σ(x) = 1 / (1 + exp(-x)).  While historically popular, sigmoid suffers from the vanishing gradient problem, where gradients become extremely small during backpropagation, hindering training, especially in deep networks.\n",
       "\n",
       "* **Tanh (Hyperbolic Tangent):**  Similar to sigmoid, tanh outputs a value between -1 and 1.  Its formula is tanh(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)).  Tanh generally performs better than sigmoid because its output is centered around 0, which can speed up training. However, it also suffers from the vanishing gradient problem.\n",
       "\n",
       "* **ReLU (Rectified Linear Unit):**  ReLU is a very popular choice due to its simplicity and effectiveness.  It outputs x if x > 0, and 0 otherwise.  Its formula is max(0, x).  ReLU avoids the vanishing gradient problem for positive inputs and is computationally efficient. However, it suffers from the \"dying ReLU\" problem, where neurons can become inactive if their weights are updated such that the input is always negative, thus preventing them from ever activating.\n",
       "\n",
       "Why is non-linearity important?\n",
       "\n",
       "Non-linearity is essential because it allows the network to learn complex relationships between inputs and outputs that cannot be represented by a linear model.  Consider a simple XOR problem:\n",
       "\n",
       "* Input (0, 0) -> Output 0\n",
       "* Input (0, 1) -> Output 1\n",
       "* Input (1, 0) -> Output 1\n",
       "* Input (1, 1) -> Output 0\n",
       "\n",
       "This problem is not linearly separable. A linear model cannot draw a line to perfectly separate the inputs that result in 0 from those that result in 1. However, a neural network with a non-linear activation function can easily learn this relationship.  The non-linear activation function allows the network to create decision boundaries that are not straight lines, enabling it to solve non-linearly separable problems.  In essence, non-linearity is what gives neural networks their power to approximate complex functions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- End of Response ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Function to Get Gemini Response ---\n",
    "def get_gemini_response_for_exam(prompt_text: str, max_words: int = 1000, model_instance=None) -> str:\n",
    "    \"\"\"\n",
    "    Generates a concise Gemini response for exam-style prompts.\n",
    "\n",
    "    Args:\n",
    "        prompt_text (str): The exam question or prompt.\n",
    "        max_words (int): Maximum number of words allowed in the response.\n",
    "        model_instance: Pre-initialized Gemini model.\n",
    "\n",
    "    Returns:\n",
    "        str: AI-generated answer or error message.\n",
    "    \"\"\"\n",
    "    if model_instance is None:\n",
    "        return \"Error: Gemini model not provided.\"\n",
    "\n",
    "    full_prompt = f\"{prompt_text}. Generate the response within {max_words} words.\"\n",
    "    print(f\"\\n--- Sending Prompt to Gemini Model ---\\n{full_prompt}\\n\")\n",
    "\n",
    "    try:\n",
    "        response = model_instance.generate_content(full_prompt)\n",
    "        generated_text = getattr(response, 'text', '') or (\n",
    "            response.candidates[0].text if response.candidates else ''\n",
    "        )\n",
    "\n",
    "        if not generated_text:\n",
    "            return \"Error: No valid response from Gemini.\"\n",
    "\n",
    "        words = generated_text.split()\n",
    "        if len(words) > max_words:\n",
    "            print(f\"--- Warning: Response Exceeded Word Limit ({len(words)} words) ---\")\n",
    "            return \" \".join(words[:max_words]) + \"\\n\\n[... Response truncated ...]\"\n",
    "        \n",
    "        print(f\"--- Gemini Response Received ({len(words)} words) ---\")\n",
    "        return generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during AI response generation: {e}\"\n",
    "\n",
    "# --- Exam Question Usage ---\n",
    "exam_prompt = (\n",
    "    \"What is an activation function in a neural network? \"\n",
    "    \"Explain its purpose, common types (ReLU, Sigmoid, Tanh), and why non-linearity is important.\"\n",
    ")\n",
    "desired_word_limit = 500\n",
    "\n",
    "print(f\"\\n--- Processing Exam Question ---\\nQuestion: {exam_prompt}\\nWord Limit: {desired_word_limit}\")\n",
    "\n",
    "exam_answer = get_gemini_response_for_exam(\n",
    "    prompt_text=exam_prompt,\n",
    "    max_words=desired_word_limit,\n",
    "    model_instance=gemini_model\n",
    ")\n",
    "\n",
    "print(\"\\n--- FINAL EXAM ANSWER ---\")\n",
    "display(Markdown(exam_answer))\n",
    "print(\"\\n--- End of Response ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985a4ddc-67b2-41fc-b381-1a5710e965ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1029a-90c4-4492-807f-288ed786916a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4c32a-cfa5-428c-a24b-a780ad8bf17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68514553-8140-4605-846f-eca4f947c58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
